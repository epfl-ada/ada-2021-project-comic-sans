{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ROOT = 'data'\n",
    "PATH_PARQUET = PATH_ROOT + '/project_datasets'\n",
    "PATH_QUOTEBANK = PATH_ROOT + '/Quotebank'\n",
    "PATH_TO_QUOTES = PATH_QUOTEBANK + '/quotes-{year}.json.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OUTPUT = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\steph\\miniconda3\\envs\\ada\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\steph\\miniconda3\\envs\\ada\\lib\\site-packages (from pyarrow) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2ciQy6i9jOp-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZEhusKde0oI"
   },
   "source": [
    "## Reading wikidata labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "nu5mKlTCfEaA",
    "outputId": "650af35b-3663-4848-ab54-ef59e4834f8d"
   },
   "outputs": [],
   "source": [
    "df_wikidata_labels = pd.read_csv(PATH_PARQUET + '/wikidata_labels_descriptions_quotebank.csv.bz2', compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnZ3lLf41f_P"
   },
   "source": [
    "## Reading speakers parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "F4U_W5Fe1n0g",
    "outputId": "c7c1cc47-56d8-4e7e-c74a-cc075d7889cb"
   },
   "outputs": [],
   "source": [
    "df_speakers = pd.read_parquet(PATH_PARQUET + '/speaker_attributes.parquet')\n",
    "df_speakers.set_index(keys='id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipVshYnHKcAG",
    "tags": []
   },
   "source": [
    "# 2. Cleaning & handling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quotes dataset is too big to process in memory at once. Here we define a method that generates a sample of speakers from the wikidata dump, along with attributes that interest us, that describe these speakers.\n",
    "Then we get their corresponding quotes from the quotebank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quotes_sample(number_of_samples=10000, year=2020,\n",
    "                           quotes_columns=['quoteID', 'quotation', 'speaker', 'qids'],\n",
    "                           speakers_columns=['date_of_birth']):\n",
    "    '''\n",
    "    Generate a sample of speakers with their attributes to their quotes.\n",
    "    \n",
    "    Some quotes have multiple qids for the speaker (for example multiple speakers with the same name).\n",
    "    We use pandas explode to treat quotes with multiple qids as a separate quote by each of the speakers.\n",
    "    '''\n",
    "    speakers_sample = df_speakers.sample(n=number_of_samples)[speakers_columns]\n",
    "    \n",
    "    merged_chunks = []\n",
    "\n",
    "    with pd.read_json(path_or_buf=PATH_TO_QUOTES.format(year=year), compression='bz2', lines=True, chunksize=500000) as df_reader:\n",
    "        for chunk in df_reader:\n",
    "            # filter the columns\n",
    "            chunk = chunk[quotes_columns]\n",
    "            # TODO: filter quotes with None speaker?\n",
    "\n",
    "            # Some quote have multiple speaker qids. need to explode that and treat them each as a separate quote\n",
    "            chunk = chunk.explode('qids')\n",
    "            merged_chunks.append(chunk.merge(right=speakers_sample, right_index=True, left_on='qids'))\n",
    "\n",
    "    sample = pd.concat(merged_chunks, ignore_index=True)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>gender</th>\n",
       "      <th>party</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-23-004492</td>\n",
       "      <td>Although not a lubricant issue, tire wear is e...</td>\n",
       "      <td>John Burke</td>\n",
       "      <td>Q15451851</td>\n",
       "      <td>[+1922-03-08T00:00:00Z]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-07-064108</td>\n",
       "      <td>The cost of getting new goodies is far too high.</td>\n",
       "      <td>John Burke</td>\n",
       "      <td>Q15451851</td>\n",
       "      <td>[+1922-03-08T00:00:00Z]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-15-102577</td>\n",
       "      <td>We have just seen the Garden of Remembrance an...</td>\n",
       "      <td>John Burke</td>\n",
       "      <td>Q15451851</td>\n",
       "      <td>[+1922-03-08T00:00:00Z]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01-011393</td>\n",
       "      <td>good bottle of French wine</td>\n",
       "      <td>John Burke</td>\n",
       "      <td>Q15451851</td>\n",
       "      <td>[+1922-03-08T00:00:00Z]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-01-014423</td>\n",
       "      <td>I thought we had a pretty good following but t...</td>\n",
       "      <td>John Burke</td>\n",
       "      <td>Q15451851</td>\n",
       "      <td>[+1922-03-08T00:00:00Z]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>2020-01-07-030083</td>\n",
       "      <td>I usually don't get caught up with things like...</td>\n",
       "      <td>Elizabeth Powell</td>\n",
       "      <td>Q5363374</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q6581072]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>2020-01-06-082102</td>\n",
       "      <td>We've lost them all but we keep getting better...</td>\n",
       "      <td>Michael Fennelly</td>\n",
       "      <td>Q6830262</td>\n",
       "      <td>[+1949-04-04T00:00:00Z]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>2020-02-18-103362</td>\n",
       "      <td>We're building a picture that feels right to us,</td>\n",
       "      <td>M. Ward</td>\n",
       "      <td>Q201514</td>\n",
       "      <td>[+1973-10-04T00:00:00Z]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>2020-01-29-093841</td>\n",
       "      <td>The vehicle was parked in Mollision Street, Be...</td>\n",
       "      <td>Scott Andrews</td>\n",
       "      <td>Q23542620</td>\n",
       "      <td>[+1994-06-30T00:00:00Z]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>2020-03-31-035898</td>\n",
       "      <td>Looking ahead, we expect consumer confidence t...</td>\n",
       "      <td>Hector Sandoval</td>\n",
       "      <td>Q56562281</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2020-01-23-004492  Although not a lubricant issue, tire wear is e...   \n",
       "1     2020-01-07-064108   The cost of getting new goodies is far too high.   \n",
       "2     2020-01-15-102577  We have just seen the Garden of Remembrance an...   \n",
       "3     2020-02-01-011393                         good bottle of French wine   \n",
       "4     2020-03-01-014423  I thought we had a pretty good following but t...   \n",
       "...                 ...                                                ...   \n",
       "8030  2020-01-07-030083  I usually don't get caught up with things like...   \n",
       "8031  2020-01-06-082102  We've lost them all but we keep getting better...   \n",
       "8032  2020-02-18-103362   We're building a picture that feels right to us,   \n",
       "8033  2020-01-29-093841  The vehicle was parked in Mollision Street, Be...   \n",
       "8034  2020-03-31-035898  Looking ahead, we expect consumer confidence t...   \n",
       "\n",
       "               speaker       qids            date_of_birth      gender party  \\\n",
       "0           John Burke  Q15451851  [+1922-03-08T00:00:00Z]  [Q6581097]  None   \n",
       "1           John Burke  Q15451851  [+1922-03-08T00:00:00Z]  [Q6581097]  None   \n",
       "2           John Burke  Q15451851  [+1922-03-08T00:00:00Z]  [Q6581097]  None   \n",
       "3           John Burke  Q15451851  [+1922-03-08T00:00:00Z]  [Q6581097]  None   \n",
       "4           John Burke  Q15451851  [+1922-03-08T00:00:00Z]  [Q6581097]  None   \n",
       "...                ...        ...                      ...         ...   ...   \n",
       "8030  Elizabeth Powell   Q5363374                     None  [Q6581072]  None   \n",
       "8031  Michael Fennelly   Q6830262  [+1949-04-04T00:00:00Z]  [Q6581097]  None   \n",
       "8032           M. Ward    Q201514  [+1973-10-04T00:00:00Z]  [Q6581097]  None   \n",
       "8033     Scott Andrews  Q23542620  [+1994-06-30T00:00:00Z]  [Q6581097]  None   \n",
       "8034   Hector Sandoval  Q56562281                     None  [Q6581097]  None   \n",
       "\n",
       "     religion  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "...       ...  \n",
       "8030     None  \n",
       "8031     None  \n",
       "8032     None  \n",
       "8033     None  \n",
       "8034     None  \n",
       "\n",
       "[8035 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We choose the column features we are interested in \n",
    "quotes_filter_columns = ['quoteID', 'quotation', 'speaker', 'qids']\n",
    "speaker_attributes_filter_columns = ['date_of_birth', 'gender', 'party', 'religion']\n",
    "\n",
    "sample = generate_quotes_sample(quotes_columns=quotes_filter_columns, speakers_columns=speaker_attributes_filter_columns)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "sample.to_csv(path_or_buf=PATH_OUTPUT + '/speakers_quotes_1000_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Who has the most quotes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qids</th>\n",
       "      <th>speaker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q6255170</th>\n",
       "      <th>John Roberts</th>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q47138769</th>\n",
       "      <th>Tua Tagovailoa</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q16235144</th>\n",
       "      <th>Joe Walsh</th>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5230773</th>\n",
       "      <th>David Anderson</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q231648</th>\n",
       "      <th>Gabrielle Union</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q42665815</th>\n",
       "      <th>Richard L. Fox</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q56418995</th>\n",
       "      <th>Ruth Kirk</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q171511</th>\n",
       "      <th>Peter Gethin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q56087342</th>\n",
       "      <th>Jordan Cowan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4993234</th>\n",
       "      <th>Thomas Holm</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count\n",
       "qids      speaker               \n",
       "Q6255170  John Roberts       679\n",
       "Q47138769 Tua Tagovailoa     363\n",
       "Q16235144 Joe Walsh          349\n",
       "Q5230773  David Anderson     331\n",
       "Q231648   Gabrielle Union    331\n",
       "...                          ...\n",
       "Q42665815 Richard L. Fox       1\n",
       "Q56418995 Ruth Kirk            1\n",
       "Q171511   Peter Gethin         1\n",
       "Q56087342 Jordan Cowan         1\n",
       "Q4993234  Thomas Holm          1\n",
       "\n",
       "[380 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_speakers = sample.groupby(by=['qids', 'speaker'])['quotation'].agg(['count'])\n",
    "grouped_speakers.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Replacing speaker attributes wikidata qids with their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since speaker attributes are only described by their qids, we need replace them by their labels to get their actual meaning. For that\n",
    "we're going to need the wikidata, and the following code shows an example of doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>male</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>Presbyterianism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1974</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>male</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>High school</td>\n",
       "      <td>Roman Catholic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_of_birth               nationality gender             party  \\\n",
       "1           1946  United States of America   male  Republican Party   \n",
       "2           1974  United States of America   male  Democratic Party   \n",
       "\n",
       "       academic_degree         religion  \n",
       "1  Bachelor of Science  Presbyterianism  \n",
       "2          High school   Roman Catholic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1946,    0,    0,    1,    0,    0],\n",
       "       [1974,    0,    0,    0,    1,    1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_features_set(QIDs, attributes_name):\n",
    "    '''\n",
    "    Creates the features dataset.\n",
    "    :param QIDs: Pandas Series with the Wikidata ids of each speaker.\n",
    "    :param attributes_name: the list of feature attributes that we're going to use for the regression\n",
    "    :return: Pandas DataFrame with the attributes used as variables (one per column).\n",
    "    '''\n",
    "    speaker_attr = df_speakers[df_speakers.index.isin(QIDs.tolist())]\n",
    "\n",
    "    attributes = {}\n",
    "    for attribute_name in attributes_name:\n",
    "        if (attribute_name != 'date_of_birth'):\n",
    "\n",
    "            attr_qids = speaker_attr[attribute_name].apply(lambda x: None if type(x) is type(None) else x[-1]) # TODO: HOW TO CHOOSE THE QIDS (PER ATTRIBUTE) WHEN THERE ARE MULTIPLES (E.G. WHEN HAVING MULTIPLE POLITICAL PARTIES)?\n",
    "            attr = df_wikidata_labels['Label'].reindex(attr_qids)\n",
    "\n",
    "            if (attribute_name == 'academic_degree'):\n",
    "                attr.fillna(value='High school', inplace=True)\n",
    "\n",
    "        else:\n",
    "            attr = speaker_attr[attribute_name].apply(lambda x: datetime.strptime(x[0], '+%Y-%m-%dT%H:%M:%S%z').year)\n",
    "\n",
    "        attributes[attribute_name] = attr.tolist()\n",
    "\n",
    "    feature_set = (pd.DataFrame(attributes)).dropna()\n",
    "    obj_columns = feature_set.select_dtypes(['object']).columns\n",
    "    feature_set[obj_columns] = feature_set[obj_columns].astype('category')\n",
    "\n",
    "    return feature_set\n",
    "\n",
    "\n",
    "# TODO: REMOVE (USED FOR TESTING)\n",
    "qids = pd.Series(['Q38111', 'Q17714', 'Q22686'])\n",
    "attr_names = ['date_of_birth', 'nationality', 'gender', 'party', 'academic_degree', 'religion']\n",
    "\n",
    "df3 = create_features_set(qids, attr_names)\n",
    "#df3.to_pickle('dataX.pkl')\n",
    "display(df3.head())\n",
    "\n",
    "cat_columns = df3.select_dtypes(['category']).columns\n",
    "df3[cat_columns] = df3[cat_columns].apply(lambda x: x.cat.codes) \n",
    "x = df3.to_numpy()\n",
    "display(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RYnFIFRMu2N"
   },
   "source": [
    "# 2. Topic labeling\n",
    "\n",
    "Zero shot classficiation using the transformers library and BART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MAyQBjjBNB35"
   },
   "outputs": [],
   "source": [
    "#!pip install pytorch\n",
    "#!pip install tensorflow\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yQ6_Md3SNOgi"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "#import json \n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_MURMAXPOCAs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# Loading the model\n",
    "classifier = transformers.pipeline('zero-shot-classification',model='xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HeRgdxrMNWCo"
   },
   "outputs": [],
   "source": [
    "# Define the attributes that belong to a certain topic and are used for classification\n",
    "labels_climate = ['climate','pollution','waste','dirty','ozone','warming','temperature']\n",
    "hypothesis_template = 'This text is about {}.' # what the model should do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OZRDMqPDNaJo"
   },
   "outputs": [],
   "source": [
    "def get_labels(data,labels,score_thresh):\n",
    "    N = len(data)\n",
    "    results = []\n",
    "    for i in range(N):\n",
    "        quote = data[i]['quotation']\n",
    "        prediction = classifier(quote, labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
    "        score = np.mean(prediction['scores'])\n",
    "        if score > score_thresh:\n",
    "            results.append(score,1) # 1 for that the quote deals with the defined topic\n",
    "        else:\n",
    "            results.append(score,0) # 0 for that the quote does not deal with the topic\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxPRQUJJOVnU"
   },
   "source": [
    "# 3. Logistic Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-dOIuZlVOYFy"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSkFf8KrYhe9"
   },
   "source": [
    "# 4. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UcmTE2huYkBz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sG4gXVibYkcT"
   },
   "source": [
    "# 5. Data Visualization & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SEIlksmVYqgU"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccqDszkcYrdc"
   },
   "source": [
    "# 6. Conludions and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "33y-ujP5Yt_o"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "milestone_2_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
