{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADA_Comic_SANS_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq8D_cEZOsWG"
      },
      "source": [
        "#!pip install pytorch\n",
        "#!pip install tensorflow\n",
        "#!pip install transformers"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgFmksMaPA25"
      },
      "source": [
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import torch"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxia-nnCW92H",
        "outputId": "ea07db28-832a-4151-b423-1308d26d4691"
      },
      "source": [
        "predict = transformers.pipeline('zero-shot-classification',model='facebook/bart-large-mnli')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l128yToIhOBH",
        "outputId": "ad741f2e-68e7-4e6a-8206-b7ed7e50936f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Money Market.gslides',\n",
              " 'Team report        Ansgar Wiechert i6172111.gdoc',\n",
              " 'Growth, debt and deficit UK, Japan, US.gslides',\n",
              " 'Businessplan.gdoc',\n",
              " 'Final Report Alternatice Investment.gdoc',\n",
              " 'EBC2121-03-Chapter4.2-Ansgar&Nika.mov',\n",
              " 'ACC - Nestle Analysis.gdoc',\n",
              " 'ACC - Nestle.gsheet',\n",
              " 'Colab Notebooks',\n",
              " 'AirThread Valuation Case.gslides',\n",
              " 'Problem_Set_3_Group_13.ipynb',\n",
              " 'Programming 2021 - Project.gdoc',\n",
              " 'Investments',\n",
              " 'quotes-2019-nytimes.json']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfNoaoLTZOAM"
      },
      "source": [
        "def get_data(path):\n",
        "  data = []\n",
        "  with open(path) as f:\n",
        "      for line in f:\n",
        "          data.append(json.loads(line))\n",
        "  return data"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOiDUlSUm1uW"
      },
      "source": [
        "labels = ['climate','pollution','waste','dirty','ozone','warming','temperature']\n",
        "hypothesis_template = 'This text is about {}.'"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjfKNKd-khGt"
      },
      "source": [
        "\"\"\" test run \"\"\"\n",
        "all = {}\n",
        "for j in range(5):\n",
        "    quote = data[j]['quotation']\n",
        "    prediction = predict(quote, labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
        "    all[quote] = sum(prediction['scores'])\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZwrabdSh_rR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684d8dfa-606e-4a9d-90f7-ad5d698fa6a2"
      },
      "source": [
        "print(all)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'It is not a low-income immigration,': 0.06475158804096282, 'a champion figure skater switching to roller skates.': 0.09562503406777978, 'It makes it much more difficult for him to make the compromises needed.': 0.5849343072623014, 'It puts me in a predicament,': 0.9215890374034643, 'A Pile of Leaves.': 1.9862750155152753}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ9OUjeZnr1G"
      },
      "source": [
        "def get_labels(data,dict,score_thresh):\n",
        "    N = len(data)\n",
        "    trues = {}\n",
        "    wrongs = {}\n",
        "    for i in range(N):\n",
        "      quote = data[i]['quotation']\n",
        "      prediction = predict(quote, labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
        "      score = sum(prediction['scores'])\n",
        "      if score > score_thresh:\n",
        "        trues[quote] = (score,1) # 1 for that the quote deals with the defined topic\n",
        "      else:\n",
        "        wrongs[quote] = (score,0) # 0 for that the quote does not deal with the topic\n",
        "        \n",
        "    return trues, wrongs\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}